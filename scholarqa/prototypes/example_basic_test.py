#!/usr/bin/env python3
"""
Ejemplo b√°sico de uso de ScholarQA sin interfaz web
Este es un prototipo para entender c√≥mo funciona el sistema
"""

import sys
from pathlib import Path

# A√±adir src al path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from core.pdf_processor import PDFProcessor
from core.embeddings import EmbeddingEngine
from core.vector_store import VectorStore
from utils.config import Config


def main():
    """Ejemplo b√°sico de procesamiento"""
    
    print("=" * 60)
    print("ScholarQA - Ejemplo B√°sico")
    print("=" * 60)
    
    # 1. Inicializar componentes
    print("\n1Ô∏è‚É£  Inicializando componentes...")
    processor = PDFProcessor()
    embedding_engine = EmbeddingEngine("sentence-transformers/all-MiniLM-L6-v2")
    vector_store = VectorStore("temp_vector_store", "test_collection")
    
    print("   ‚úì Componentes inicializados")
    
    # 2. Simular procesamiento de texto (sin PDF real)
    print("\n2Ô∏è‚É£  Procesando texto de ejemplo...")
    
    sample_text = """
    Machine learning is a subset of artificial intelligence that focuses on the 
    development of algorithms and statistical models that enable computers to 
    perform tasks without explicit instructions. Deep learning, a subset of 
    machine learning, uses neural networks with multiple layers to progressively 
    extract higher-level features from raw input.
    
    Natural language processing (NLP) is another important area of AI that deals 
    with the interaction between computers and human language. It enables 
    computers to understand, interpret, and generate human language in a 
    valuable way.
    """
    
    # 3. Crear chunks
    chunks = processor.chunk_text(sample_text, chunk_size=200, chunk_overlap=50)
    print(f"   ‚úì Texto dividido en {len(chunks)} chunks")
    
    # 4. A√±adir a vector store
    print("\n3Ô∏è‚É£  Almacenando en base de datos vectorial...")
    metadatas = [
        {"source": "example.txt", "chunk_id": i} 
        for i in range(len(chunks))
    ]
    vector_store.add_documents(chunks, metadatas)
    print(f"   ‚úì {len(chunks)} documentos almacenados")
    
    # 5. Hacer queries de prueba
    print("\n4Ô∏è‚É£  Probando b√∫squeda sem√°ntica...")
    
    queries = [
        "What is machine learning?",
        "Tell me about neural networks",
        "How does NLP work?"
    ]
    
    for query in queries:
        print(f"\n   üîç Query: {query}")
        results = vector_store.query(query, n_results=2)
        
        if results['documents'][0]:
            best_match = results['documents'][0][0]
            print(f"   üìù Mejor resultado: {best_match[:100]}...")
        else:
            print("   ‚ùå No se encontraron resultados")
    
    # 6. Estad√≠sticas
    print("\n5Ô∏è‚É£  Estad√≠sticas:")
    print(f"   üìä Total documentos: {vector_store.get_collection_count()}")
    print(f"   üìè Dimensi√≥n embeddings: {embedding_engine.dimension}")
    
    # 7. Limpiar
    print("\n6Ô∏è‚É£  Limpiando recursos temporales...")
    vector_store.delete_collection()
    
    import shutil
    if Path("temp_vector_store").exists():
        shutil.rmtree("temp_vector_store")
    
    print("   ‚úì Limpieza completada")
    
    print("\n" + "=" * 60)
    print("‚úÖ Ejemplo completado exitosamente!")
    print("=" * 60)
    print("\nüí° Ahora prueba:")
    print("   - python src/app.py (interfaz web)")
    print("   - python src/cli.py upload <pdf> (procesar PDF real)")
    print()


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° Aseg√∫rate de haber ejecutado:")
        print("   pip install -r requirements.txt")
        sys.exit(1)
