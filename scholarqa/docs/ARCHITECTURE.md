# Arquitectura de ScholarQA

## ğŸ—ï¸ VisiÃ³n General

ScholarQA es un sistema de RAG (Retrieval-Augmented Generation) que permite hacer preguntas sobre documentos PDF acadÃ©micos usando modelos de IA completamente locales.

## ğŸ“Š Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Usuario                              â”‚
â”‚                    (Web UI / CLI)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flask Application                         â”‚
â”‚                      (src/app.py)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                        â”‚
         â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Processor   â”‚                    â”‚   LLM Engine     â”‚
â”‚ (pdf_processor)  â”‚                    â”‚  (llm_engine)    â”‚
â”‚                  â”‚                    â”‚                  â”‚
â”‚  - Extract text  â”‚                    â”‚  - Generate text â”‚
â”‚  - Chunk text    â”‚                    â”‚  - Answer Q&A    â”‚
â”‚  - Metadata      â”‚                    â”‚  - llama.cpp     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                        â”‚
         â–¼                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚ Embedding Engine â”‚                              â”‚
â”‚  (embeddings)    â”‚                              â”‚
â”‚                  â”‚                              â”‚
â”‚  - Sentence      â”‚                              â”‚
â”‚    Transformers  â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
         â”‚                                        â”‚
         â–¼                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vector Store (ChromaDB)                        â”‚
â”‚                  (vector_store)                             â”‚
â”‚                                                             â”‚
â”‚  - Store embeddings                                         â”‚
â”‚  - Semantic search                                          â”‚
â”‚  - Retrieve context                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Flujo de Datos

### 1. Ingesta de Documentos

```
PDF File â†’ PDFProcessor.extract_text() â†’ Raw Text
                                           â†“
                              PDFProcessor.chunk_text() â†’ Text Chunks
                                           â†“
                           EmbeddingEngine.encode() â†’ Embeddings
                                           â†“
                           VectorStore.add_documents() â†’ Stored in ChromaDB
```

### 2. Respuesta a Preguntas

```
User Question â†’ EmbeddingEngine.encode() â†’ Query Embedding
                                             â†“
                          VectorStore.query() â†’ Relevant Chunks
                                             â†“
                    LLMEngine.create_qa_prompt() â†’ Formatted Prompt
                                             â†“
                        LLMEngine.generate() â†’ Answer
                                             â†“
                              Flask â†’ User Interface
```

## ğŸ“¦ Componentes Principales

### 1. PDFProcessor (`src/core/pdf_processor.py`)

**Responsabilidad:** Procesamiento de archivos PDF

**Funciones principales:**
- `extract_text(pdf_path)`: Extrae texto de un PDF
- `extract_metadata(pdf_path)`: Extrae metadatos (tÃ­tulo, autor, etc.)
- `chunk_text(text, chunk_size, overlap)`: Divide el texto en fragmentos

**Dependencias:**
- pypdf: Lectura de PDFs
- pdfplumber: ExtracciÃ³n avanzada (opcional)

### 2. EmbeddingEngine (`src/core/embeddings.py`)

**Responsabilidad:** GeneraciÃ³n de embeddings vectoriales

**Funciones principales:**
- `encode(texts)`: Genera embeddings para mÃºltiples textos
- `encode_single(text)`: Genera embedding para un texto

**Modelo por defecto:**
- `all-MiniLM-L6-v2` (384 dimensiones, 80MB)
- Alternativa: `all-mpnet-base-v2` (768 dimensiones, mejor calidad)

### 3. VectorStore (`src/core/vector_store.py`)

**Responsabilidad:** Almacenamiento y bÃºsqueda vectorial

**Funciones principales:**
- `add_documents(texts, metadatas, ids)`: AÃ±ade documentos
- `query(query_text, n_results)`: BÃºsqueda semÃ¡ntica
- `get_collection_count()`: Cuenta documentos

**Base de datos:**
- ChromaDB (local, persistente)
- UbicaciÃ³n: `data/vector_store/`

### 4. LLMEngine (`src/core/llm_engine.py`)

**Responsabilidad:** GeneraciÃ³n de respuestas con LLM local

**Funciones principales:**
- `generate(prompt, max_tokens, ...)`: GeneraciÃ³n de texto
- `answer_question(question, context)`: Q&A con contexto
- `create_qa_prompt(question, context)`: Formato de prompts

**Modelos soportados:**
- Cualquier modelo GGUF (llama.cpp)
- TinyLlama, Mistral, Llama 2, etc.

### 5. Flask Application (`src/app.py`)

**Responsabilidad:** API web y frontend

**Endpoints:**
- `GET /`: Interfaz web
- `GET /api/status`: Estado del sistema
- `POST /api/upload`: Subir PDF
- `POST /api/ask`: Hacer pregunta
- `GET /api/documents`: Listar documentos

## ğŸ”§ ConfiguraciÃ³n (`src/utils/config.py`)

Gestiona todas las variables de configuraciÃ³n desde `.env`:

```python
- EMBEDDING_MODEL: Modelo de embeddings
- LLM_MODEL: Ruta al modelo LLM
- CHROMA_PERSIST_DIR: Directorio ChromaDB
- CHUNK_SIZE: TamaÃ±o de chunks
- CHUNK_OVERLAP: Overlap entre chunks
- MAX_TOKENS: Tokens mÃ¡ximos de respuesta
- TEMPERATURE: Temperature del LLM
```

## ğŸ—‚ï¸ Estructura de Datos

### Chunk Metadata

```python
{
    'source': 'paper.pdf',
    'chunk_id': 0,
    'title': 'Paper Title'
}
```

### Query Response

```python
{
    'answer': 'Generated answer...',
    'sources': [{'source': 'paper.pdf', 'chunk_id': 0}],
    'context_used': 5
}
```

## ğŸš€ Optimizaciones

### Actuales
- Lazy loading de componentes
- Chunking con overlap para contexto
- Embeddings cacheados por Sentence Transformers
- ChromaDB persistente

### Futuras
- Cache de embeddings de queries frecuentes
- Batch processing para mÃºltiples PDFs
- Reranking de resultados
- CuantizaciÃ³n de modelos

## ğŸ”’ Privacidad y Seguridad

- **100% Local**: NingÃºn dato sale de tu mÃ¡quina
- **Sin APIs externas**: No se envÃ­a informaciÃ³n a servicios cloud
- **Datos persistentes**: Vector store local en disco
- **Sin tracking**: No hay analytics ni telemetrÃ­a

## ğŸ“ˆ Escalabilidad

### LÃ­mites actuales
- ~1000 PDFs en memoria
- ChromaDB soporta millones de vectores
- Depende de RAM disponible

### Para escalar
- Usar ChromaDB en modo cliente-servidor
- Implementar paginaciÃ³n en queries
- Batch processing asÃ­ncrono

## ğŸ› ï¸ TecnologÃ­as

| Componente | TecnologÃ­a | Licencia |
|------------|------------|----------|
| Framework Web | Flask | BSD |
| Embeddings | Sentence Transformers | Apache 2.0 |
| Vector DB | ChromaDB | Apache 2.0 |
| LLM Runtime | llama.cpp | MIT |
| PDF Processing | PyPDF | BSD |
| Frontend | Vanilla JS | - |

## ğŸ“ Decisiones de DiseÃ±o

### Â¿Por quÃ© ChromaDB?
- FÃ¡cil de usar
- Completamente local
- Excelente para prototipos y producciÃ³n
- Sin configuraciÃ³n compleja

### Â¿Por quÃ© llama.cpp?
- Mejor rendimiento CPU
- Soporte GGUF amplio
- Baja huella de memoria
- Comunidad activa

### Â¿Por quÃ© Sentence Transformers?
- Modelos pre-entrenados excelentes
- FÃ¡cil integraciÃ³n
- Caching automÃ¡tico
- Soporte multilingÃ¼e

### Â¿Por quÃ© Flask?
- Simple y ligero
- FÃ¡cil de entender
- Sin dependencias complejas
- Perfecto para proyectos educativos

## ğŸ”„ Ciclo de Vida

1. **InicializaciÃ³n**: Cargar modelos y configuraciÃ³n
2. **Ingesta**: Procesar PDFs y almacenar embeddings
3. **Query**: BÃºsqueda semÃ¡ntica + generaciÃ³n LLM
4. **Respuesta**: Formato y entrega al usuario

## ğŸ§ª Testing

- Unit tests: Cada componente independiente
- Integration tests: Flujo completo
- E2E tests: Interfaz web

## ğŸ“š Referencias

- [LangChain Docs](https://python.langchain.com/)
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
